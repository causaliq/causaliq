{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to CausalIQ","text":""},{"location":"#research-mission","title":"Research Mission","text":"<p>This research addresses fundamental challenges in causal discovery: How can we discover causal relationships from observational data more accurately and transparently? By combining rigorous statistical methods with AI reasoning capabilities, this project aims to create tools that help researchers across disciplines uncover the causal mechanisms underlying their data.</p>"},{"location":"#core-research-areas","title":"Core Research Areas","text":""},{"location":"#causal-discovery-bayesian-networks","title":"\ud83d\udd17 Causal Discovery &amp; Bayesian Networks","text":"<p>Developing and improving algorithms for learning causal graph structures from observational data, with a focus on score-based methods, constraint-based approaches, and hybrid techniques.</p>"},{"location":"#ai-enhanced-causal-reasoning","title":"\ud83e\udd16 AI-Enhanced Causal Reasoning","text":"<p>Exploring how Large Language Models can augment traditional statistical methods by incorporating domain knowledge, suggesting causal directions, and providing interpretable explanations.</p>"},{"location":"#methodological-innovation","title":"\ud83d\udcca Methodological Innovation","text":"<p>Creating robust, reproducible workflows for causal discovery experiments, with emphasis on stability analysis, uncertainty quantification, and performance evaluation.</p>"},{"location":"#research-philosophy","title":"Research Philosophy","text":"<p>We believe that the future of causal discovery lies in the thoughtful integration of statistical rigour with artificial intelligence. By combining the precision of mathematical algorithms with the contextual understanding of language models, we can create more robust, interpretable, and useful tools for understanding, and making reasoned decisions, in our world.</p>"},{"location":"#open-science-commitment","title":"Open Science Commitment","text":"<p>All research outputs\u2014code, data, and results\u2014are made freely available to support reproducible research and collaborative advancement of the field.</p>"},{"location":"#interdisciplinary-impact","title":"Interdisciplinary Impact","text":"<p>This work aims to benefit researchers across domains: from epidemiologists studying disease causation to economists analyzing policy effects to machine learning researchers building more robust AI systems.</p>"},{"location":"#get-involved","title":"Get Involved","text":"<p>Collaboration: We welcome discussions with researchers working on related problems. Feel free to reach out through GitHub Discussions on any of the project repositories.</p> <p>Open Source: All projects are open source and accept contributions. See the development guidelines for details on how to contribute.</p> <p>Academic Partnerships: We're interested in collaborations with research groups working on causal inference, Bayesian networks, or AI-assisted scientific discovery.</p> <p>\"Understanding causation is fundamental to science, policy, and human reasoning. By building better tools for causal discovery, we can help researchers across disciplines make more reliable inferences about the mechanisms that drive their domains of study.\"</p>"},{"location":"#for-llms","title":"\ud83e\udde0 For LLMs","text":"<p>This documentation is designed to:</p> <ul> <li>Help LLMs understand the overall mission of the CausalIQ Projects.</li> </ul>"},{"location":"#get-in-touch","title":"\ud83d\udceb Get in Touch","text":"<ul> <li>GitHub Discussions (on individual repos)</li> </ul>"},{"location":"about/","title":"Dr. Ken Kitson","text":""},{"location":"about/#research-profile","title":"Research Profile","text":"<p>I am an independent researcher and research visitor at Queen Mary University of London, specializing in causal discovery and Bayesian network structure learning. My work bridges the gap between traditional statistical methods and modern artificial intelligence to advance our understanding of causation in complex systems.</p>"},{"location":"about/#academic-background","title":"Academic Background","text":"<p>Current Position - Research Visitor, Queen Mary University of London - Independent Researcher, CausalIQ</p> <p>Research Interests</p> <ul> <li>Causal discovery and inference</li> <li>Bayesian network structure learning  </li> <li>Score-based and constraint-based algorithms</li> <li>AI-enhanced statistical methods</li> <li>Reproducible research methodologies</li> <li>Open science and collaborative research</li> </ul>"},{"location":"about/#research-philosophy","title":"Research Philosophy","text":"<p>I believe that understanding causation is fundamental to scientific progress and evidence-based decision making. My work focuses on developing methods that are:</p> <ul> <li>Statistically rigorous: Grounded in solid mathematical foundations</li> <li>Computationally efficient: Scalable to real-world datasets</li> <li>Interpretable: Providing clear insights into causal mechanisms</li> <li>Reproducible: Supporting open science and collaborative research</li> <li>Practically useful: Addressing real problems across disciplines</li> </ul>"},{"location":"about/#methodological-focus","title":"Methodological Focus","text":""},{"location":"about/#statistical-foundations","title":"Statistical Foundations","text":"<p>My research builds on established statistical theory for causal inference, including:</p> <ul> <li>Graphical models and d-separation</li> <li>Conditional independence testing</li> <li>Score-based structure learning (BIC, AIC, BDeu)</li> <li>Constraint-based algorithms (PC, FCI)</li> <li>Hybrid approaches combining multiple paradigms</li> </ul>"},{"location":"about/#ai-integration","title":"AI Integration","text":"<p>I explore how modern AI techniques can enhance traditional causal discovery:</p> <ul> <li>Large language models for domain knowledge integration</li> <li>Natural language processing for causal reasoning</li> <li>Automated interpretation and explanation generation</li> <li>Human-AI collaborative workflows</li> </ul>"},{"location":"about/#reproducibility-open-science","title":"Reproducibility &amp; Open Science","text":"<p>All research is conducted with reproducibility in mind:</p> <ul> <li>Open source implementations of all algorithms</li> <li>Comprehensive experimental protocols</li> <li>Version-controlled datasets and results</li> <li>Detailed documentation and tutorials</li> </ul>"},{"location":"about/#collaboration-mentoring","title":"Collaboration &amp; Mentoring","text":"<p>I'm committed to fostering the next generation of researchers in causal inference. I welcome:</p> <ul> <li>Student collaborations: Working with graduate students on research projects</li> <li>Academic partnerships: Joint projects with research groups</li> <li>Industry collaboration: Applying causal methods to real-world problems</li> <li>Open source contributions: Community-driven development of tools</li> </ul>"},{"location":"about/#contact-collaboration","title":"Contact &amp; Collaboration","text":"<p>I'm always interested in discussing research ideas and potential collaborations. Please reach out through:</p> <ul> <li>GitHub Discussions on relevant project repositories</li> <li>Academic conferences and workshops</li> <li>Research seminars and invited talks</li> </ul> <p>\"The pursuit of causal understanding requires both mathematical rigor and creative thinking. By combining traditional statistical methods with modern AI capabilities, we can build tools that help researchers across disciplines make better causal inferences.\"</p>"},{"location":"about/development-methodology/","title":"LLM-Assisted Development Methodology","text":"<p>The CausalIQ research ecosystem employs Large Language Models (LLMs) as development partners to enhance code quality, accelerate research implementation, and maintain consistency across projects while preserving human oversight and understanding.</p>"},{"location":"about/development-methodology/#research-philosophy","title":"Research Philosophy","text":""},{"location":"about/development-methodology/#augmented-development-approach","title":"Augmented Development Approach","text":"<ul> <li>Human-AI collaboration: LLMs augment rather than replace developer expertise</li> <li>Incremental transparency: All AI-suggested changes are explained and reviewable</li> <li>Quality preservation: Rigorous standards maintained regardless of development method</li> <li>Knowledge transfer: LLM interactions designed to enhance developer understanding</li> </ul>"},{"location":"about/development-methodology/#methodological-benefits","title":"Methodological Benefits","text":"<ul> <li>Consistency across ecosystem: Uniform coding patterns across multiple research packages</li> <li>Documentation completeness: AI assistance ensures comprehensive code documentation</li> <li>Test coverage: Systematic test generation following established patterns</li> <li>Code quality: Automated adherence to style guides and best practices</li> </ul>"},{"location":"about/development-methodology/#development-standards","title":"Development Standards","text":""},{"location":"about/development-methodology/#change-management-principles","title":"Change Management Principles","text":"<p>Incremental Development: LLM suggestions are constrained to focused, understandable modifications (&lt;50 lines) to maintain developer comprehension and code review effectiveness.</p> <p>Explanation Requirements: Every proposed change includes:</p> <ul> <li>Clear problem statement and solution rationale</li> <li>Impact assessment on existing functionality  </li> <li>Alternative approaches considered</li> <li>Integration implications across the ecosystem</li> </ul>"},{"location":"about/development-methodology/#quality-assurance-framework","title":"Quality Assurance Framework","text":"<p>Automated Validation: All LLM-generated code passes:</p> <ul> <li>Black formatting with 79-character line limits</li> <li>isort import organization following Python conventions</li> <li>mypy type checking for complete type safety</li> <li>flake8 style validation for code clarity</li> </ul> <p>Testing Methodology: Systematic test generation across three categories:</p> <ul> <li>Unit tests: Isolated function validation with mocked dependencies</li> <li>Functional tests: Integration with local system resources</li> <li>Integration tests: End-to-end validation with external services</li> </ul>"},{"location":"about/development-methodology/#research-applications","title":"Research Applications","text":""},{"location":"about/development-methodology/#causal-discovery-enhancement","title":"Causal Discovery Enhancement","text":"<p>LLM assistance accelerates implementation of novel causal discovery algorithms while maintaining statistical rigor through:</p> <ul> <li>Algorithm validation: Systematic testing against known benchmarks</li> <li>Documentation generation: Clear explanations of methodological choices</li> <li>Performance optimization: Efficient implementations suitable for research datasets</li> </ul>"},{"location":"about/development-methodology/#domain-knowledge-integration","title":"Domain Knowledge Integration","text":"<p>AI-assisted development enables sophisticated integration of expert knowledge with statistical methods:</p> <ul> <li>Natural language constraints: Convert domain expertise into algorithmic constraints</li> <li>Contextual interpretation: Meaningful variable and relationship naming</li> <li>Explanation generation: Automated research summaries and methodology descriptions</li> </ul>"},{"location":"about/development-methodology/#reproducible-research-infrastructure","title":"Reproducible Research Infrastructure","text":"<p>LLM assistance ensures research reproducibility through:</p> <ul> <li>Consistent interfaces: Standardized APIs across analysis packages</li> <li>Comprehensive documentation: Complete usage examples and parameter explanations</li> <li>Test coverage: Validation of research claims through systematic testing</li> </ul>"},{"location":"about/development-methodology/#academic-benefits","title":"Academic Benefits","text":""},{"location":"about/development-methodology/#research-velocity","title":"Research Velocity","text":"<ul> <li>Rapid prototyping: Faster implementation of research ideas</li> <li>Documentation completeness: Thorough explanations support reproducibility</li> <li>Error reduction: Systematic testing catches implementation issues early</li> </ul>"},{"location":"about/development-methodology/#collaboration-enhancement","title":"Collaboration Enhancement","text":"<ul> <li>Code readability: Consistent style enables easier collaboration</li> <li>Knowledge sharing: Well-documented implementations transfer insights effectively</li> <li>Standard compliance: Adherence to best practices facilitates peer review</li> </ul>"},{"location":"about/development-methodology/#methodological-innovation","title":"Methodological Innovation","text":"<ul> <li>Novel approaches: AI assistance enables exploration of complex integration patterns</li> <li>Quality maintenance: High standards preserve academic credibility</li> <li>Scalable practices: Consistent methodology supports ecosystem growth</li> </ul>"},{"location":"about/development-methodology/#implementation-framework","title":"Implementation Framework","text":""},{"location":"about/development-methodology/#context-provision-strategy","title":"Context Provision Strategy","text":"<p>Effective LLM collaboration requires comprehensive context including:</p> <ul> <li>Ecosystem architecture: Understanding of package interactions and dependencies</li> <li>Research objectives: Clear problem statements and methodological goals  </li> <li>Technical constraints: Performance requirements and compatibility needs</li> <li>Quality standards: Coding conventions and testing requirements</li> </ul>"},{"location":"about/development-methodology/#collaborative-workflow","title":"Collaborative Workflow","text":"<ol> <li>Problem decomposition: Breaking complex research tasks into manageable components</li> <li>Incremental implementation: Step-by-step development with human oversight</li> <li>Systematic validation: Testing at unit, functional, and integration levels</li> <li>Documentation integration: Ensuring research artifacts support reproducibility</li> </ol>"},{"location":"about/development-methodology/#results-and-impact","title":"Results and Impact","text":"<p>This methodology enables the CausalIQ ecosystem to maintain research quality while leveraging AI capabilities for:</p> <ul> <li>Accelerated development cycles supporting rapid research iteration</li> <li>Enhanced code quality through systematic application of best practices</li> <li>Improved reproducibility via comprehensive documentation and testing</li> <li>Scalable collaboration through consistent development patterns</li> </ul> <p>The approach demonstrates how AI assistance can enhance rather than compromise academic rigor, providing a framework for responsible AI integration in computational research environments.</p> <p>This methodology represents ongoing research into effective human-AI collaboration patterns for academic software development, balancing innovation with scientific reproducibility requirements.</p>"},{"location":"about/logos/","title":"Logo Ideas","text":""},{"location":"about/logos/#initial-concepts","title":"Initial Concepts","text":""},{"location":"about/logos/#colour-palettes","title":"Colour Palettes","text":""},{"location":"about/logos/#mkdocs-palette","title":"mkdocs palette","text":""},{"location":"about/logos/#chart-palette","title":"chart Palette","text":""},{"location":"papers/","title":"Publications &amp; Papers","text":""},{"location":"papers/#peer-reviewed-publications","title":"Peer-Reviewed Publications","text":""},{"location":"papers/#2025","title":"2025","text":"<p>\"Stable structure learning with HC-Stable and Tabu-Stable algorithms\"</p> <ul> <li>International Journal of Approximate Reasoning</li> <li>Introduces Tabu-Stable, a novel score-based Bayesian Network structure learning algorithm that eliminates instability due to variable ordering, achieving consistent and superior performance across datasets and variable types</li> <li>Paper | Code</li> </ul> <p>\"Decoding the mechanisms of the Hattrick football manager game using Bayesian network structure learning for optimal decision-making\" (Under Review)</p> <ul> <li>Entertainment Computing </li> <li>This paper applies Bayesian Network structure learning to uncover and model the hidden mechanics of the online football manager game Hattrick, combining data and domain knowledge to explain and simulate game behaviour.</li> <li>Preprint </li> </ul> <p>\"Causal discovery using dynamically requested knowledge\"</p> <ul> <li>Knowledge-Based Systems </li> <li>Introduces a dynamic knowledge integration approach for Causal Bayesian Network learning, where the algorithm actively requests expert input during learning, improving structural accuracy and transparency over existing methods.</li> <li>Paper | Code</li> </ul> <p>\"Using GPT-4 to guide causal machine learning\"</p> <ul> <li>Expert Systems with Applications </li> <li>Evaluating GPT-4\u2019s ability to infer causal relationships from variable labels alone shows it produces expert-like causal graphs and, when combined with causal ML, improves data-driven causal discovery accuracy and trustworthiness.</li> <li>Paper</li> </ul> <p>\"Investigating potential causes of Sepsis with Bayesian network structure learning\"</p> <ul> <li>Applied Intelligence </li> <li>Combining hospital data with clinical expertise, this study uses Bayesian Network structure learning and model averaging to identify causal risk factors for Sepsis, revealing policy-relevant relationships and achieving strong predictive performance.</li> <li>Paper</li> </ul> <p>Past years to be completed</p>"},{"location":"papers/#conference-presentations","title":"Conference Presentations","text":""},{"location":"papers/#2024","title":"2024","text":""},{"location":"papers/#journal-reviewing","title":"Journal Reviewing","text":"<p>*To be completed *</p>"},{"location":"papers/#conference-reviewing","title":"Conference Reviewing","text":"<ul> <li>PGM (2026)</li> </ul>"},{"location":"papers/#current-collaborations","title":"Current Collaborations","text":"<ul> <li>Queen Mary University of London: Host institution for research visit</li> </ul> <p>This publication record reflects a commitment to rigorous, reproducible research at the intersection of causal inference and artificial intelligence, with emphasis on practical applications and open science principles.</p>"},{"location":"projects/","title":"CausalIQ Projects","text":"<p>The CausalIQ ecosystem consists of several interconnected projects, each focusing on specific aspects of causal discovery and inference. These projects can be used independently or together to create comprehensive causal analysis workflows.</p>"},{"location":"projects/#current-projects","title":"\ud83d\udee0\ufe0f Current Projects","text":""},{"location":"projects/#causaliq-workflow","title":"\ud83e\udd16 CausalIQ Workflow","text":"<p>Comprehensive framework for designing, executing, and reproducing causal discovery experiments at scale, with built-in support for distributed computing and result tracking.</p>"},{"location":"projects/#zenodo-synchronisation","title":"\ud83d\udd04 Zenodo Synchronisation","text":"<p>Automated tools for synchronizing research datasets, experiment configurations, and results with Zenodo for scientific transparency and reproducibility and storage of large files.</p>"},{"location":"projects/#causaliq-data","title":"\ud83d\udd22 CausalIQ Data","text":"<p>High-performance implementations of data-related functions, including caching of data, in-memory randomisation and sub-sampling of data, as well as scoring functions (e.g. BIC, BDeu) and independence tests based on the data.</p>"},{"location":"projects/#coming-soon","title":"\ud83d\ude80 Coming Soon","text":""},{"location":"projects/#causaliq-analysis-starting-december-2025","title":"\ud83d\udcca CausalIQ Analysis [starting December 2025]","text":"<p>Tools for analyzing and visualizing learned causal graphs, including structural metrics, stability assessment, and publication-ready visualizations.</p>"},{"location":"projects/#causaliq-papers-starting-december-2025","title":"\ud83e\uddea CausalIQ Papers [starting December 2025]","text":"<p>Curated collection of experimental setups, benchmark datasets, and published results that enable reproducible research and method comparison.</p>"},{"location":"projects/#causaliq-knowledge-starting-january-2026","title":"\ud83e\udde0 CausalIQ Knowledge [starting January 2026]","text":"<p>Novel approaches for integrating Large Language Models and human knowledge with statistical causal discovery, enabling domain knowledge incorporation and natural language explanation of results.</p>"},{"location":"projects/#causaliq-discovery","title":"\ud83d\udd0d CausalIQ Discovery","text":"<p>Provides state-of-the-art algorithms for learning causal graph structures from observational data</p>"},{"location":"projects/#causaliq-predict","title":"\ud83d\udd2e CausalIQ Predict","text":"<p>Tools for analyzing and visualizing learned causal graphs, including structural metrics, stability assessment, and publication-ready visualizations.</p>"},{"location":"projects/#project-ecosystem","title":"Project Ecosystem","text":"<pre><code>graph TD\n    DIS[\ud83d\udd0d CausalIQ Discovery]\n    KNO[\ud83e\udde0 CausalIQ Knowledge]\n    WOR[\ud83e\udd16 CausalIQ Workflow]\n    ANA[\ud83d\udcca CausalIQ Analysis] \n    PAP[\ud83e\uddea CausalIQ Papers]\n    DAT[\ud83d\udd22 CausalIQ Data]\n    PRE[\ud83d\udd2e CausalIQ Predict]\n    ZEN[\ud83d\udd04 Zenodo Sync]\n\n    PAP --&gt; ZEN\n    PAP --&gt; WOR\n    WOR --&gt; DIS\n    WOR --&gt; ANA\n    WOR --&gt; ZEN\n    WOR --&gt; PRE\n    PRE --&gt; KNO\n    DIS --&gt; KNO\n    ANA --&gt; KNO\n    DIS --&gt; DAT\n    ANA --&gt; DAT\n\n</code></pre>"},{"location":"projects/#getting-started","title":"Getting Started","text":""},{"location":"projects/#for-researchers","title":"For Researchers","text":"<ol> <li>Start with Discovery: Install <code>causaliq-discovery</code> to explore basic causal learning</li> <li>Add Analysis: Use <code>causaliq-analysis</code> for visualization and evaluation</li> <li>Scale Up: Implement <code>causaliq-workflow</code> for larger experiments</li> <li>Enhance with AI: Integrate <code>causaliq-knowledge</code> for domain knowledge incorporation</li> </ol>"},{"location":"projects/#for-developers","title":"For Developers","text":"<ol> <li>Read the Architecture: Understand how projects interact</li> <li>Choose Your Focus: Pick a project that matches your interests</li> <li>Follow Guidelines: Use our development standards and practices</li> <li>Contribute: Submit issues, feature requests, or pull requests</li> </ol>"},{"location":"projects/#potential-application-areas","title":"Potential Application Areas","text":"<p>These projects may be useful in research across multiple domains:</p> <ul> <li>Medical Research: Learning disease networks and treatment mechanisms</li> <li>Economics: Understanding macroeconomic relationships and policy effects</li> <li>Biology: Discovering gene regulatory networks and protein interactions</li> <li>Social Sciences: Analyzing social phenomena and intervention effects</li> <li>Business: Identifying key performance drivers and optimization opportunities</li> </ul> <p>The CausalIQ project ecosystem provides a comprehensive toolkit for causal discovery research, combining statistical rigor with modern software engineering practices to support reproducible, scalable causal inference.</p>"},{"location":"projects/data/","title":"\ud83d\udd22 CausalIQ Data Project","text":"<p>The CausalIQ Data project provides the data-related capabilities that causal discovery requires. These are:</p> <ul> <li>data import and caching - data can be imported from standard  tabular formats (comma-separated variables) and cached for high performance</li> <li>graph scoring - provide graph score derived from the data which is  the objective function used by score-based structure learning algorithms. This is   based upon how likely the data is to be seen for a given graph, typically  modified by a penalty for complex graphs (e.g. BIC score), or modified  by a prior belief about the graph strcuture (e.g. BDeu score)</li> <li>independence tests - used to determine conditional independence tests  which are intrinsic to the operataion of constraint-based structure  learning algorithms.</li> </ul> <p>Quick Links:</p> <ul> <li>\ud83d\udcd6 Full Documentation</li> <li>\ud83d\udcbb Repository</li> <li>\ud83d\ude80 Quick Start - coming soon</li> </ul>"},{"location":"projects/data/#upcoming-key-innovations","title":"Upcoming Key Innovations","text":""},{"location":"projects/data/#plugin-architecture","title":"\ud83e\udde9 Plugin Architecture","text":"<ul> <li>use by third-party software - ability to use these data capabilities in third party structure learning algorithms so that comparisons are based on a common scoring or conditional independence framework, and performance optimisations speed up third-party algorithms.</li> </ul>"},{"location":"projects/data/#stability-integration","title":"\ud83c\udfdb\ufe0f Stability Integration","text":"<ul> <li>Stable scores - stable resolution of equal-score situations for unstable algorithms e.g. Tabu</li> </ul>"},{"location":"projects/data/#llm-assisted-causal-discovery","title":"\ud83e\udde0 LLM-assisted Causal Discovery","text":"<ul> <li>Data values - Data values and variable names may provide part of the context for LLM-assisted causal discovery</li> <li>Knowledge integration - incorporation of LLM and human expertise in scores and priors via the CausalIQ Knowledge package. </li> <li>Relationship explanations: Natural language descriptions of relationships in data</li> </ul>"},{"location":"projects/data/#optimised-performance","title":"\u26a1Optimised Performance","text":"<ul> <li>GPU Data provider - support for optimised data handling on GPU hardware</li> <li>Intelligent data scanning - reduce number of full-row data scans</li> </ul>"},{"location":"projects/data/#enhanced-distribution-support","title":"\ud83c\udfb2 Enhanced Distribution Support","text":"<ul> <li>Mixed Types: scores and independence tests that support mixtures of continuous and categorical variables</li> </ul>"},{"location":"projects/data/#integration-with-causaliq-ecosystem","title":"Integration with CausalIQ Ecosystem","text":"<ul> <li>\ud83d\udd0d CausalIQ Discovery makes use of this package to provide objective functions and conditional independence tests for structure learning algorithms.</li> <li>\ud83e\uddea CausalIQ Analysis uses score functions as part of the evaluation of learnt graphs.</li> <li>\ud83d\udc8e CausalIQ Core makes use of the BNFit interface to estimate parameters based on data.</li> <li>\ud83e\udd16 CausalIQ Workflow uses the in-memory randomisation of this package for stability experiments.</li> </ul> <p>CausalIQ Data represents the foundational data processing layer that enables robust, high-performance causal discovery through optimized scoring functions, conditional independence testing, and seamless integration across the entire CausalIQ ecosystem.</p>"},{"location":"projects/discovery/","title":"\ud83d\udd0d CausalIQ Discovery","text":"<p>CausalIQ Discovery provides algorithms for learning causal graph structures from observational data. There is a focus on simple, stable and competitive algorithms.</p> <p>Quick Links:</p> <ul> <li>\ud83d\udcd6 Full Documentation - coming soon</li> <li>\ud83d\udcbb Repository - coming soon</li> <li>\ud83d\ude80 Quick Start - coming soon</li> </ul>"},{"location":"projects/discovery/#proposed-features","title":"\ud83d\ude80 Proposed Features","text":"<ul> <li>score-based HC and Tabu algorithms</li> <li>Support for discrete and continuous data types</li> <li>Stability enhancements so that results not dependent on arbitrary artifacts of the data (e.g. variable order)</li> <li>Active learning whereby algorithm can dynamically request knowledge in areas of uncertainty.</li> </ul>"},{"location":"projects/discovery/#integration-with-ecosystem","title":"Integration with Ecosystem","text":"<ul> <li>\ud83c\udfaf CausalIQ Data (causaliq-data is used by this package to determine the score of graphs.</li> <li>\ud83e\udd16 CausalIQ Workflow uses this package in structure learning workflows.</li> </ul>"},{"location":"projects/discovery/#standalone-use","title":"Standalone Use","text":"<p>Users may use this package standalone in one-off structure learning experiments, as part of their own workflows, or as steps within CausalIQ Workflows</p> <p></p> <p>CausalIQ Discovery provides the statistical foundation for the entire ecosystem, implementing proven algorithms with modern software engineering practices to support reliable causal discoverye research.</p>"},{"location":"projects/ecosystem_architecture/","title":"CausalIQ Ecosystem Architecture","text":""},{"location":"projects/ecosystem_architecture/#overview","title":"Overview","text":"<p>The CausalIQ ecosystem is designed as a modular framework for causal discovery research that seamlessly integrates statistical algorithms with Large Language Models (LLMs). The architecture emphasizes modularity, reproducibility, and human-AI collaboration to advance the field of causal inference and Bayesian network structure learning.</p>"},{"location":"projects/ecosystem_architecture/#architecture-principles","title":"Architecture Principles","text":""},{"location":"projects/ecosystem_architecture/#modularity","title":"\ud83d\udd27 Modularity","text":"<p>Each project can be used independently, allowing researchers to adopt specific components without requiring the entire ecosystem.</p>"},{"location":"projects/ecosystem_architecture/#interoperability","title":"\ud83d\udd17 Interoperability","text":"<p>Projects integrate seamlessly through standardized APIs, data formats, and shared configuration patterns.</p>"},{"location":"projects/ecosystem_architecture/#reproducibility","title":"\ud83d\udd2c Reproducibility","text":"<p>Open-source design with versioned datasets, experiment configurations, and results synchronized via Zenodo.</p>"},{"location":"projects/ecosystem_architecture/#human-ai-collaboration","title":"\ud83e\udd1d Human-AI Collaboration","text":"<p>Statistical causal discovery algorithms are enhanced by LLM reasoning for interpretation, direction inference, and domain knowledge integration.</p>"},{"location":"projects/ecosystem_architecture/#ecosystem-components","title":"Ecosystem Components","text":""},{"location":"projects/ecosystem_architecture/#core-projects","title":"Core Projects","text":"<pre><code>causaliq-papers (Datasets, experiments and results for papers)\n\u251c\u2500\u2500 causaliq-workflow (Orchestration &amp; workflow management)\n\u251c\u2500\u2500 causaliq-discovery (Statistical algorithms &amp; structure learning)\n\u251c\u2500\u2500 causaliq-data (Optimized data caching, score functions and independence tests)\n\u251c\u2500\u2500 causaliq-analysis (Metrics &amp; statistical analysis)\n\u251c\u2500\u2500 causaliq-knowledge (LLM integration &amp; reasoning)\n\u251c\u2500\u2500 causaliq-core (Graphs, Bayesian Networks and utilities)\n\u2514\u2500\u2500 zenodo-sync (Dataset &amp; result synchronization)\n</code></pre>"},{"location":"projects/ecosystem_architecture/#project-responsibilities","title":"Project Responsibilities","text":"Project Purpose Key Features causaliq-discovery Core statistical algorithms Bayesian network learning, score-based methods causaliq-data Data related functions Data caching, scoring and indepedence tests causaliq-analysis Result analysis Metrics, stability analysis, graph comparison causaliq-knowledge LLM integration Graph generation, causal direction inference causaliq-workflow Workflow orchestration CI workflow inspired, DASK task management causaliq-papers Research outputs Published configurations, datasets, results causaliq-core Shared code Graph representations and utility functions zenodo-sync Data management Automated synchronization with Zenodo"},{"location":"projects/ecosystem_architecture/#data-flow-architecture","title":"Data Flow Architecture","text":""},{"location":"projects/ecosystem_architecture/#1-input-stage","title":"1. Input Stage","text":"<ul> <li>Raw datasets: Observational and experimental data</li> <li>Domain knowledge: Expert-provided causal relationships</li> <li>LLM priors: Generated initial graphs from metadata</li> <li>Configuration: Experiment parameters and algorithm settings</li> </ul>"},{"location":"projects/ecosystem_architecture/#2-processing-stage","title":"2. Processing Stage","text":"<ul> <li>Statistical learning: Score-based structure learning algorithms</li> <li>LLM guidance: Causal direction suggestions and constraint generation</li> <li>Hybrid reasoning: Integration of statistical evidence with domain knowledge</li> <li>Optimization: Graph search and scoring function evaluation</li> </ul>"},{"location":"projects/ecosystem_architecture/#3-evaluation-stage","title":"3. Evaluation Stage","text":"<ul> <li>Scoring: BIC, AIC, BDeu, and custom metrics</li> <li>Stability analysis: Bootstrap sampling and edge confidence</li> <li>Comparison: Against ground truth and baseline methods</li> <li>Validation: Cross-validation and holdout testing</li> </ul>"},{"location":"projects/ecosystem_architecture/#4-output-stage","title":"4. Output Stage","text":"<ul> <li>Learned graphs: Final Bayesian network structures</li> <li>Metrics: Performance statistics and confidence measures</li> <li>Interpretations: LLM-generated explanations and insights</li> <li>Reports: Automated analysis summaries</li> </ul>"},{"location":"projects/ecosystem_architecture/#5-storage-stage","title":"5. Storage Stage","text":"<ul> <li>Version control: Git-based experiment tracking</li> <li>Zenodo sync: Automated dataset and result archival</li> <li>Metadata: Rich annotations for reproducibility</li> </ul>"},{"location":"projects/ecosystem_architecture/#integration-patterns","title":"Integration Patterns","text":""},{"location":"projects/ecosystem_architecture/#api-standards","title":"API Standards","text":"<ul> <li>Graph representation: NetworkX-compatible formats</li> <li>Data interfaces: Pandas DataFrame standards</li> <li>Configuration: YAML/JSON schema validation</li> <li>Scoring: Consistent function signatures</li> </ul>"},{"location":"projects/ecosystem_architecture/#communication-protocols","title":"Communication Protocols","text":"<ul> <li>Inter-project: REST APIs and message queues</li> <li>LLM integration: OpenAI-compatible interfaces</li> <li>Workflow: Dask distributed computing</li> <li>Storage: Cloud-native object storage</li> </ul>"},{"location":"projects/ecosystem_architecture/#shared-data-structures","title":"Shared Data Structures","text":"<pre><code># Example graph representation\ngraph = {\n    \"nodes\": [\"X1\", \"X2\", \"X3\"],\n    \"edges\": [(\"X1\", \"X2\"), (\"X2\", \"X3\")],\n    \"metadata\": {\n        \"algorithm\": \"pc\",\n        \"score\": \"bic\",\n        \"confidence\": 0.95\n    }\n}\n</code></pre>"},{"location":"projects/ecosystem_architecture/#llm-integration-architecture","title":"LLM Integration Architecture","text":""},{"location":"projects/ecosystem_architecture/#llm-capabilities","title":"\ud83e\udde0 LLM Capabilities","text":"<ul> <li>Graph generation: Initial structures from domain descriptions</li> <li>Causal direction: Arrow orientation suggestions</li> <li>Interpretation: Natural language explanations</li> <li>Constraint generation: Domain-informed restrictions</li> <li>Report writing: Automated experimental summaries</li> </ul>"},{"location":"projects/ecosystem_architecture/#human-llm-workflow","title":"\ud83d\udd04 Human-LLM Workflow","text":"<ol> <li>Human specification: Natural language experiment description</li> <li>LLM parsing: Structured configuration generation</li> <li>Statistical learning: Algorithm execution with LLM constraints</li> <li>LLM interpretation: Results explanation and insights</li> <li>Human validation: Expert review and refinement</li> </ol>"},{"location":"projects/ecosystem_architecture/#deployment-patterns","title":"Deployment Patterns","text":""},{"location":"projects/ecosystem_architecture/#research-environment","title":"\ud83d\udd2c Research Environment","text":"<ul> <li>Local development: Individual project installation</li> <li>Jupyter integration: Interactive analysis notebooks</li> <li>Academic clusters: HPC job submission</li> </ul>"},{"location":"projects/ecosystem_architecture/#cloud-deployment","title":"\u2601\ufe0f Cloud Deployment","text":"<ul> <li>Container orchestration: Docker/Kubernetes</li> <li>Serverless functions: Event-driven processing</li> <li>Managed services: Cloud-native ML platforms</li> </ul>"},{"location":"projects/ecosystem_architecture/#enterprise-integration","title":"\ud83c\udfe2 Enterprise Integration","text":"<ul> <li>API gateways: Secure external access</li> <li>Data pipelines: ETL/ELT integration</li> <li>Monitoring: Observability and logging</li> </ul>"},{"location":"projects/ecosystem_architecture/#quality-assurance","title":"Quality Assurance","text":""},{"location":"projects/ecosystem_architecture/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Unit tests: Individual function validation</li> <li>Integration tests: Cross-project compatibility</li> <li>Performance tests: Scalability benchmarks</li> <li>Reproducibility tests: Result consistency validation</li> </ul>"},{"location":"projects/ecosystem_architecture/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>API documentation: OpenAPI specifications</li> <li>User guides: Getting started tutorials</li> <li>Developer docs: Contribution guidelines</li> <li>Research papers: Algorithmic foundations</li> </ul>"},{"location":"projects/ecosystem_architecture/#future-extensions","title":"Future Extensions","text":""},{"location":"projects/ecosystem_architecture/#planned-enhancements","title":"Planned Enhancements","text":"<ul> <li>Real-time learning: Streaming data processing</li> <li>Federated learning: Distributed causal discovery</li> <li>Multi-modal data: Text, images, time series</li> <li>Causal reasoning: Counterfactual inference</li> </ul>"},{"location":"projects/ecosystem_architecture/#research-directions","title":"Research Directions","text":"<ul> <li>LLM fine-tuning: Domain-specific causal models</li> <li>Active learning: Experimental design optimization</li> <li>Uncertainty quantification: Bayesian model averaging</li> <li>Scalability: Large-scale graph learning</li> </ul> <p>This architecture document provides the blueprint for the CausalIQ ecosystem, enabling both human researchers and LLMs to understand and contribute to the framework's development and application.</p>"},{"location":"projects/ecosystem_roadmap/","title":"CausalIQ Ecosystem - Development Roadmap","text":"<p>At-a-glance view of development releases across the CausalIQ ecosystem</p> <p>Last updated: December 04, 2025</p>"},{"location":"projects/ecosystem_roadmap/#current-ecosystem-status","title":"\ud83c\udf1f Current Ecosystem Status","text":"Project Current Release Project capabilities Detailed Roadmap causaliq (Main) 0.1 Architecture Architecture and development standards defined n/a causaliq-workflow 0.2 Basic CLI Basic CLI with real-time execution feedback here causaliq-core 0.2 Graphs Utility functions and graph classes (SDG, PDAG, DAG) tbd zenodo-sync 0.1 Foundation Follows CausalIQ standards tbd causaliq-repo-template 1.0 Foundation Defines standardised project docs, structure and CI testing n/a <p>All other projects not yet started.</p> <p>Milestones:</p> <ul> <li>end-March 2026: CausalIQ LLM-assisted model-averaging experiments &amp; results for conference paper</li> <li>end-April 2026: Charts and Tables for CausalIQ LLM-assisted model-averaging paper</li> <li>end-September 2026: Experiments and results for another paper</li> <li>end-2026: Full reproducibility of key published papers with assets on Zenodo</li> </ul>"},{"location":"projects/ecosystem_roadmap/#ecosystem-development-timeline","title":"\ud83d\udcca Ecosystem Development Timeline","text":""},{"location":"projects/ecosystem_roadmap/#december-2025-monolith-migration-graph-averaging","title":"December 2025 - Monolith Migration &amp; Graph Averaging","text":"Project Release Status Key Deliverables causaliq-data 0.1 Foundation Data \ud83d\udcdd Planned Data, NumPy and Pandas classes and BNFit interface causaliq-core 0.3 Bayesian Networks \ud83d\udcdd Planned BNs and i/o, using BNFit interface causaliq-analysis 0.1 Foundation \u2728 Envisaged Action interface supported causaliq-analysis 0.2 Structural Metrics \u2728 Envisaged Structural graph metrics from monolith causaliq-analysis 0.3 Graph Averaging \u2728 Envisaged Probabilistic graph averaging causaliq-data 0.2 Scores \ud83d\udcdd Planned Score functions migrated with plugin architecture <p>Code migrated from legacy monolithic repo will be modified to meet CausalIQ quality standards.</p> <p>CausalIQ packages (excluding core) will implement the CausalIQ Action interface and therefore can be included in CausalIQ Workflows</p>"},{"location":"projects/ecosystem_roadmap/#january-2026-llm-causal-knowledge-i","title":"January 2026 - LLM Causal Knowledge I","text":"Project Release Status Key Deliverables causal-analysis 0.4 Averaging Analysis \u2728 Envisaged Basic analysis of graph averaging causal-knowledge 0.1 Foundation \u2728 Envisaged Requirements and technical architecture causal-knowledge 0.2 LLM APIs \u2728 Envisaged Some LLMs integrated causal-knowledge 0.3 Simple Edge Queries \u2728 Envisaged Simple Edge Queries - existence/orientation causal-knowledge 0.4 Query Database \u2728 Envisaged Query, context, response stored causaliq-workflow 0.3 Enhanced Workflow \ud83d\udd04 Background Conservative execution and dry-run capability causaliq-workflow 0.4 Progress and Summary \ud83d\udd04 Background Real-time progress tracking and execution summary causaliq-workflow 0.5 Advanced Features \u2728 Envisaged Metadata, compare mode, timeouts, estimated completion"},{"location":"projects/ecosystem_roadmap/#february-2026-llm-causal-knowledge-ii","title":"February 2026 - LLM Causal Knowledge II","text":"Project Release Status Key Deliverables causal-analysis 0.4 LLM Analysis \u2728 Envisaged Based on January Experience causal-knowledge 0.5 Advanced Queries \u2728 Envisaged Based on January Experience causaliq-papers 0.1 Import graph \u2728 Envisaged Import graphs from monolithic repo"},{"location":"projects/ecosystem_roadmap/#future-vision-post-february-2026","title":"\ud83d\ude80 Future Vision Post February 2026","text":""},{"location":"projects/ecosystem_roadmap/#research-platform-features","title":"Research Platform Features","text":"<ul> <li>LLM Integration: Model averaging, hypothesis generation with causal reasoning</li> <li>Web Interface: Browser-based workflow designer for non-technical researchers  </li> <li>Publication Support: Reproducible research outputs with automated documentation</li> </ul>"},{"location":"projects/ecosystem_roadmap/#advanced-capabilities","title":"Advanced Capabilities","text":"<ul> <li>Workflow Marketplace: Sharing and discovering research workflow templates</li> <li>Interactive Notebooks: Jupyter integration with workflow execution</li> <li>Multi-machine Execution: Distributed workflows across compute clusters</li> <li>AI-assisted Optimisation: Automated hyperparameter and workflow tuning</li> <li>Integration Ecosystem: Plugins for major research tools and platforms</li> </ul>"},{"location":"projects/ecosystem_roadmap/#performance-scale","title":"Performance &amp; Scale","text":"<ul> <li>High-performance Computing: GPU acceleration for large-scale structure learning</li> <li>Distributed Storage: Cloud-native knowledge bases with global accessibility</li> <li>Real-time Analytics: Live causal discovery with streaming data sources</li> <li>Enterprise Features: Security, compliance, and enterprise-grade deployment</li> </ul> <p>This roadmap is updated weekly and reflects current development priorities. For detailed project-specific roadmaps, see individual project documentation.</p>"},{"location":"projects/knowledge/","title":"\ud83e\udde0 CausalIQ Knowledge Project","text":"<p>The CausalIQ Knowledge project represents a novel approach to causal discovery by combining the traditional statistical structure learning algorithms with the contextual understanding and reasoning capabilities of Large Language Models. This integration enables more interpretable, domain-aware, and human-friendly causal discovery workflows.</p> <p>Quick Links:</p> <ul> <li>\ud83d\udcd6 Full Documentation - coming soon</li> <li>\ud83d\udcbb Repository - coming soon</li> <li>\ud83d\ude80 Quick Start - coming soon</li> </ul>"},{"location":"projects/knowledge/#possible-key-innovations","title":"Possible Key Innovations","text":""},{"location":"projects/knowledge/#domain-knowledge-integration","title":"\ud83e\udde0 Domain Knowledge Integration","text":"<ul> <li>Natural language constraints: Specify domain knowledge in plain English</li> <li>Expert knowledge incorporation: Convert expert understanding into algorithmic constraints</li> <li>Contextual graph interpretation: Understanding variable meanings and relationships</li> </ul>"},{"location":"projects/knowledge/#interactive-discovery","title":"\ud83d\udd04 Interactive Discovery","text":"<ul> <li>Conversational interfaces: Query causal relationships in natural language</li> <li>Hypothesis testing: Test specific causal hypotheses through dialogue</li> <li>Iterative refinement: Collaboratively improve causal models through interaction</li> </ul>"},{"location":"projects/knowledge/#automated-explanation","title":"\ud83d\udcdd Automated Explanation","text":"<ul> <li>Relationship explanations: Natural language descriptions of discovered causal links</li> <li>Uncertainty communication: Clear explanation of confidence levels and limitations</li> <li>Report generation: Automated research summaries and methodology descriptions</li> </ul>"},{"location":"projects/knowledge/#upcoming-integration-with-ecosystem","title":"Upcoming Integration with Ecosystem","text":"<ul> <li>\ud83d\udd0d CausalIQ Discovery makes use of this package to learn more  accurate graphs.</li> <li>\ud83e\uddea CausalIQ Analysis uses this package to explain the learning process, intelligently combine end explain results.</li> <li>\ud83d\udd2e CausalIq Predict uses this package to explain predictions made by learnt models.</li> </ul> <p>The LLM Integration project represents a significant step toward more intelligent, interpretable, and human-collaborative approaches to causal discovery, bridging the gap between statistical rigor and domain expertise.</p>"},{"location":"projects/workflow/","title":"\ud83e\udd16 CausalIQ Workflow","text":"<p>The CausalIQ Workflow framework provides a comprehensive solution for designing, executing, and reproducing causal discovery experiments at scale. Built on modern workflow orchestration tools, it enables researchers to conduct rigorous, reproducible studies while managing complex experimental configurations and large-scale computations.</p> <p>Quick Links:</p> <ul> <li>\ud83d\udcd6 Full Documentation</li> <li>\ud83d\udcbb Repository</li> <li>\ud83d\ude80 Quick Start - coming soon</li> </ul>"},{"location":"projects/workflow/#key-features","title":"Key Features","text":""},{"location":"projects/workflow/#workflow-orchestration","title":"\ud83d\udd04 Workflow Orchestration","text":"<ul> <li>Continuous Integration (CI) testing: Workflow specification syntax</li> <li>Dask distributed computing: Scalable parallel processing</li> <li>Dependency management: Automatic handling of data and processing dependencies</li> <li>Error recovery: Robust handling of failures and restarts</li> </ul>"},{"location":"projects/workflow/#experiment-management","title":"\ud83d\udcca Experiment Management","text":"<ul> <li>Configuration management: YAML-based experiment specifications</li> <li>Parameter sweeps: Systematic exploration of algorithm parameters</li> <li>Version control: Git-based tracking of experiments and results</li> <li>Reproducibility: Deterministic execution with seed management</li> </ul>"},{"location":"projects/workflow/#results-tracking","title":"\ud83d\udcc8 Results Tracking","text":"<ul> <li>Automated metrics: Comprehensive evaluation of learned structures</li> <li>Comparison frameworks: Statistical comparison across methods</li> <li>Visualization: Interactive plots and publication-ready figures</li> <li>Report generation: Automated experimental summaries</li> </ul>"},{"location":"projects/workflow/#integration-with-ecosystem","title":"Integration with Ecosystem","text":"<ul> <li>\ud83d\udd0d CausalIQ Discovery (causaliq-discovery) is called by this package to perform structure learning.</li> <li>\ud83d\udcca CausalIQ Analysis (causaliq-predict) is called by this package to perform results analysis and generate assets for research papers.</li> <li>\ud83d\udd2e CausalIQ Predict (causaliq-predict) is called by this package to perform causal prediction.</li> <li>\ud83d\udd04 Zenodo Synchronisation (zenodo-sync) is used by this package to download datasets and upload results.</li> <li>\ud83e\uddea CausalIQ Papers (causaliq-papers) are defined in terms of CausalIQ Workflows allowing the reproduction of experiments, results and published paper assets created by the CausalIQ ecosystem.</li> </ul> <p>The CausalIQ Workflow framework enables reproducible, scalable causal discovery research by providing comprehensive tools for experiment design, execution, and analysis, supporting the advancement of reliable causal inference methodologies.</p>"},{"location":"projects/zenodo/","title":"\ud83d\udd04Zenodo Synchronisation","text":"<p>A lightweight CLI and Python library to synchronise local research data, results and analysis artifacts with Zenodo. Designed for reproducible science and seamless data publishing workflows.</p> <p>Quick Links:</p> <ul> <li>\ud83d\udcd6 Full Documentation - coming soon</li> <li>\ud83d\udcbb Repository</li> <li>\ud83d\ude80 Quick Start</li> </ul>"},{"location":"projects/zenodo/#features-under-development","title":"Features (under development)","text":"<ul> <li>\ud83d\udce4 Upload &amp; Publish: Upload metadata, READMEs, and digital assets from local filesystem to Zenodo</li> <li>\ud83d\udce5 Download: Download published datasets to local filesystem for reproducible research</li> <li>\ud83d\udd04 Sync: Bidirectional synchronization between local directories and Zenodo records</li> <li>\ud83d\udd10 Authentication: Secure API token-based authentication with Zenodo</li> <li>\ud83e\uddea Sandbox Support: Test your workflows safely with Zenodo's sandbox environment</li> <li>\ud83c\udfaf Semantic Versioning: Built-in support for semantic versioning of your research outputs</li> <li>\ud83d\udc0d Python API: Comprehensive Python API for integration into existing workflows</li> <li>\u2328\ufe0f CLI Interface: Easy-to-use command-line interface for quick operations</li> </ul>"},{"location":"projects/zenodo/#integration-with-ecosystem","title":"Integration with Ecosystem","text":"<ul> <li>\ud83e\udd16 CausalIQ Workflow (causaliq-workflow) makes use of this package (zenodo-sync) to download datasets and intermediate results required for experimental workflows, and to upload new results and analysis to Zenodo.</li> <li>\ud83e\uddea CausalIQ Papers (causaliq-papers) are defined in terms of CausalIQ Workflows allowing the reproduction of experiments, results and published paper assets created by the CausalIQ ecosystem.</li> </ul>"},{"location":"projects/zenodo/#standalone-use","title":"Standalone Use","text":"<ul> <li>\ud83c\udf10 Zenodo Synchronisation is general-purpose software which can synchronise any local resources with Zenodo deposits.</li> </ul> <p>Zenodo Synchronisation streamlines research data management for the ecosystem, offering robust, general-purpose tools to automate and simplify Zenodo repository synchronization with modern software engineering practices.</p>"},{"location":"research/","title":"Research Overview","text":"<p>This section provides accessible explanations of the key concepts, methods, and innovations in causal discovery research that form the foundation of the CausalIQ ecosystem.</p>"},{"location":"research/#core-research-areas","title":"Core Research Areas","text":""},{"location":"research/#causal-discovery","title":"Causal Discovery","text":"<p>Understanding how to uncover causal relationships from observational data, including the fundamental challenges and modern algorithmic approaches.</p>"},{"location":"research/#bayesian-networks","title":"Bayesian Networks","text":"<p>Graphical models that represent probabilistic relationships between variables, providing a framework for reasoning under uncertainty.</p>"},{"location":"research/#llm-integration","title":"LLM Integration","text":"<p>Novel approaches for combining Large Language Models with traditional statistical methods to enhance causal reasoning and interpretation.</p>"},{"location":"research/#research-philosophy","title":"Research Philosophy","text":"<p>The research presented here is guided by several key principles:</p> <p>Statistical Rigour: All methods are grounded in solid mathematical foundations, with careful attention to assumptions and limitations.</p> <p>Practical Applicability: While theoretically sound, the focus is on developing methods that solve real-world problems across multiple domains.</p> <p>Interpretability: Emphasis on methods that provide clear, understandable insights into causal mechanisms rather than black-box predictions.</p> <p>Reproducibility: All research follows open science principles with publicly available code, data, and comprehensive documentation.</p> <p>Interdisciplinary Impact: Developing tools and methods that benefit researchers across domains, from medicine to economics to social sciences.</p>"},{"location":"research/#methodological-innovations","title":"Methodological Innovations","text":""},{"location":"research/#hybrid-statistical-ai-approaches","title":"Hybrid Statistical-AI Approaches","text":"<p>Combining the precision of statistical algorithms with the contextual understanding of artificial intelligence to create more robust and interpretable causal discovery methods.</p>"},{"location":"research/#stability-and-uncertainty-analysis","title":"Stability and Uncertainty Analysis","text":"<p>Developing comprehensive frameworks for assessing the reliability and uncertainty of discovered causal relationships through bootstrap analysis and sensitivity testing.</p>"},{"location":"research/#scalable-algorithms","title":"Scalable Algorithms","text":"<p>Creating efficient implementations that can handle large variable sets and datasets while maintaining statistical validity.</p>"},{"location":"research/#domain-integration","title":"Domain Integration","text":"<p>Methods for incorporating domain knowledge and expert understanding into algorithmic causal discovery processes.</p>"},{"location":"research/#applications","title":"Applications","text":"<p>The research has applications across numerous domains:</p> <ul> <li>Medical Research: Understanding disease mechanisms and treatment effects</li> <li>Policy Analysis: Evaluating the causal impact of interventions and policies  </li> <li>Business Intelligence: Identifying the drivers of key performance metrics</li> <li>Scientific Discovery: Uncovering causal mechanisms in natural and social phenomena</li> <li>Machine Learning: Building more robust and interpretable AI systems</li> </ul>"},{"location":"research/#future-directions","title":"Future Directions","text":"<p>Future research directions might include:</p> <ul> <li>Real-time Causal Discovery: Methods for learning causal relationships from streaming data</li> <li>Federated Learning: Privacy-preserving causal discovery across distributed datasets</li> <li>Multi-modal Integration: Incorporating text, images, and other data types into causal analysis</li> <li>Automated Scientific Discovery: AI systems that can autonomously generate and test causal hypotheses</li> </ul> <p>This research aims to advance both the theoretical understanding and practical application of causal discovery, creating tools that help researchers across disciplines make more reliable inferences about the causal mechanisms underlying their data.</p>"},{"location":"research/bayesian-networks/","title":"Bayesian Networks: A Gentle Introduction","text":"<p>Bayesian networks are powerful graphical models that represent probabilistic relationships between variables. They provide an intuitive way to model complex systems where variables influence each other through causal relationships.</p>"},{"location":"research/bayesian-networks/#what-are-bayesian-networks","title":"What Are Bayesian Networks?","text":"<p>A Bayesian network consists of:</p> <ol> <li>Nodes: Representing random variables in your system</li> <li>Directed edges: Representing direct causal or probabilistic dependencies</li> <li>Conditional probability tables: Quantifying the strength of relationships</li> </ol>"},{"location":"research/bayesian-networks/#visual-representation","title":"Visual Representation","text":"<pre><code>      Weather\n     \u2199      \u2198\nSprinkler    Rain\n     \u2198      \u2199 \n     Grass Wet\n</code></pre> <p>This simple network shows that:</p> <ul> <li>Weather influences both Sprinkler usage and Rain</li> <li>Both Sprinkler and Rain affect whether the Grass is Wet</li> </ul>"},{"location":"research/bayesian-networks/#key-properties","title":"Key Properties","text":""},{"location":"research/bayesian-networks/#1-directed-acyclic-graph-dag","title":"1. Directed Acyclic Graph (DAG)","text":"<ul> <li>Edges have direction (arrows)</li> <li>No cycles are allowed</li> <li>This ensures logical consistency in causal relationships</li> </ul>"},{"location":"research/bayesian-networks/#2-local-independence","title":"2. Local Independence","text":"<p>Each variable is independent of its non-descendants given its parents. This dramatically reduces the complexity of representing joint probability distributions.</p>"},{"location":"research/bayesian-networks/#3-factorization","title":"3. Factorization","text":"<p>The joint probability can be written as:</p> <p>\\(P(X_1, X_2, ..., X_n) = \\prod_{i=1}^{n} P(X_i | \\text{Parents}(X_i))\\)</p>"},{"location":"research/bayesian-networks/#types-of-bayesian-networks","title":"Types of Bayesian Networks","text":""},{"location":"research/bayesian-networks/#discrete-networks","title":"Discrete Networks","text":"<p>Variables take on categorical values (e.g., True/False, High/Medium/Low).</p> <p>Example: Medical diagnosis <pre><code>Pollution     Smoking\n     \u2198        \u2199 \n     Lung Cancer\n     \u2199         \u2198\nCough     X-ray Result\n</code></pre></p>"},{"location":"research/bayesian-networks/#continuous-networks","title":"Continuous Networks","text":"<p>Variables are continuous (e.g., temperature, income, age).</p> <p>Example: Economic modeling <pre><code>Education \u2192 Income\n    \u2193        \u2193\nEmployment \u2192 Spending\n</code></pre></p>"},{"location":"research/bayesian-networks/#hybrid-networks","title":"Hybrid Networks","text":"<p>Mix of discrete and continuous variables with appropriate conditional distributions.</p>"},{"location":"research/bayesian-networks/#learning-bayesian-networks","title":"Learning Bayesian Networks","text":""},{"location":"research/bayesian-networks/#structure-learning","title":"Structure Learning","text":"<p>The process of discovering the graph structure from data.</p> <p>Challenges:</p> <ul> <li>Exponentially many possible structures</li> <li>Statistical equivalence (multiple structures can represent the same independence relationships)</li> <li>Need to balance model complexity with fit to data</li> </ul> <p>Approaches:</p> <ol> <li>Score-based: Search for structure with best score (BIC, BDeu, etc.)</li> <li>Constraint-based: Use independence tests to determine structure</li> <li>Hybrid: Combine both approaches</li> </ol>"},{"location":"research/bayesian-networks/#parameter-learning","title":"Parameter Learning","text":"<p>Once structure is known, estimate conditional probability tables from data.</p> <p>For discrete variables: Count frequencies and smooth</p> <p>For continuous variables: Fit appropriate distributions (e.g., Gaussian)</p>"},{"location":"research/bayesian-networks/#practical-applications","title":"Practical Applications","text":""},{"location":"research/bayesian-networks/#medical-diagnosis","title":"Medical Diagnosis","text":"<pre><code>Symptoms \u2192 Disease \u2192 Test Results\n</code></pre> <ul> <li>Model relationships between symptoms, diseases, and test outcomes</li> <li>Support diagnostic decision-making</li> <li>Handle uncertainty in medical knowledge</li> </ul>"},{"location":"research/bayesian-networks/#risk-assessment","title":"Risk Assessment","text":"<pre><code>Environmental Factors \u2192 Risk Factors \u2192 Adverse Outcomes\n</code></pre> <ul> <li>Model complex risk pathways</li> <li>Quantify uncertainty in risk estimates</li> <li>Support decision-making under uncertainty</li> </ul>"},{"location":"research/bayesian-networks/#quality-control","title":"Quality Control","text":"<pre><code>Process Variables \u2192 Product Quality \u2192 Customer Satisfaction\n</code></pre> <ul> <li>Model manufacturing processes</li> <li>Identify key quality drivers</li> <li>Optimize process parameters</li> </ul>"},{"location":"research/bayesian-networks/#financial-modeling","title":"Financial Modeling","text":"<pre><code>Economic Indicators \u2192 Market Conditions \u2192 Investment Returns\n</code></pre> <ul> <li>Model financial markets and investment risks</li> <li>Portfolio optimization under uncertainty</li> <li>Scenario analysis and stress testing</li> </ul>"},{"location":"research/bayesian-networks/#advantages-of-bayesian-networks","title":"Advantages of Bayesian Networks","text":""},{"location":"research/bayesian-networks/#1-interpretability","title":"1. Interpretability","text":"<p>The graph structure provides clear visual representation of relationships, making it easy to understand and communicate results.</p>"},{"location":"research/bayesian-networks/#2-uncertainty-quantification","title":"2. Uncertainty Quantification","text":"<p>Natural handling of uncertainty through probability distributions, allowing for principled decision-making under uncertainty.</p>"},{"location":"research/bayesian-networks/#3-incremental-updates","title":"3. Incremental Updates","text":"<p>New evidence can be efficiently incorporated using Bayesian updating, making the models adaptive to new information.</p>"},{"location":"research/bayesian-networks/#4-missing-data","title":"4. Missing Data","text":"<p>Graceful handling of missing data through marginalization, avoiding the need for imputation in many cases.</p>"},{"location":"research/bayesian-networks/#5-causal-reasoning","title":"5. Causal Reasoning","text":"<p>When structure reflects causal relationships, networks support intervention and counterfactual reasoning.</p>"},{"location":"research/bayesian-networks/#challenges-and-limitations","title":"Challenges and Limitations","text":""},{"location":"research/bayesian-networks/#computational-complexity","title":"Computational Complexity","text":"<ul> <li>Inference can be exponential in network size</li> <li>Structure learning is NP-hard</li> <li>Need for approximation methods in large networks</li> </ul>"},{"location":"research/bayesian-networks/#assumptions","title":"Assumptions","text":"<ul> <li>Assumes variables can be adequately represented as nodes</li> <li>Requires conditional independence assumptions</li> <li>Static structure (though dynamic extensions exist)</li> </ul>"},{"location":"research/bayesian-networks/#data-requirements","title":"Data Requirements","text":"<ul> <li>Need sufficient data for reliable parameter estimation</li> <li>Structure learning requires large samples for complex networks</li> <li>Quality of results depends on data quality</li> </ul>"},{"location":"research/bayesian-networks/#modern-extensions","title":"Modern Extensions","text":""},{"location":"research/bayesian-networks/#dynamic-bayesian-networks","title":"Dynamic Bayesian Networks","text":"<p>Model systems that evolve over time by replicating network structure across time slices.</p>"},{"location":"research/bayesian-networks/#object-oriented-bayesian-networks","title":"Object-Oriented Bayesian Networks","text":"<p>Handle repeated structures and relationships in complex domains.</p>"},{"location":"research/bayesian-networks/#causal-bayesian-networks","title":"Causal Bayesian Networks","text":"<p>Explicitly model causal relationships, supporting intervention and counterfactual analysis.</p>"},{"location":"research/bayesian-networks/#getting-started","title":"Getting Started","text":""},{"location":"research/bayesian-networks/#1-define-your-problem","title":"1. Define Your Problem","text":"<ul> <li>What variables are important?</li> <li>What relationships do you expect?</li> <li>What decisions do you need to support?</li> </ul>"},{"location":"research/bayesian-networks/#2-collect-data","title":"2. Collect Data","text":"<ul> <li>Ensure sufficient sample size</li> <li>Include all relevant variables</li> <li>Handle missing data appropriately</li> </ul>"},{"location":"research/bayesian-networks/#3-choose-learning-approach","title":"3. Choose Learning Approach","text":"<ul> <li>Structure learning vs. expert knowledge</li> <li>Discrete vs. continuous variables</li> <li>Computational constraints</li> </ul>"},{"location":"research/bayesian-networks/#4-validate-results","title":"4. Validate Results","text":"<ul> <li>Cross-validation for predictive accuracy</li> <li>Expert review of learned structure</li> <li>Sensitivity analysis for key parameters</li> </ul>"},{"location":"research/bayesian-networks/#5-apply-and-iterate","title":"5. Apply and Iterate","text":"<ul> <li>Use network for inference and decision support</li> <li>Update with new data and knowledge</li> <li>Refine structure based on experience</li> </ul> <p>Bayesian networks provide a principled framework for reasoning under uncertainty. By combining graph theory, probability theory, and computational methods, they offer powerful tools for modeling complex systems across many domains.</p>"},{"location":"research/causal-discovery/","title":"Understanding Causal Discovery","text":"<p>Causal discovery is the process of learning causal relationships from observational data. Unlike traditional statistical analysis that focuses on correlation and prediction, causal discovery aims to uncover the underlying mechanisms that generate the observed data.</p>"},{"location":"research/causal-discovery/#why-causal-discovery-matters","title":"Why Causal Discovery Matters","text":""},{"location":"research/causal-discovery/#beyond-correlation","title":"Beyond Correlation","text":"<p>While correlation tells us that two variables tend to change together, causation tells us that changing one variable will actually influence the other. This distinction is crucial for:</p> <ul> <li>Scientific understanding: Identifying the mechanisms behind natural phenomena</li> <li>Policy making: Predicting the effects of interventions before implementing them</li> <li>Medical research: Understanding how treatments affect patient outcomes</li> <li>Business decisions: Knowing which actions will actually drive desired results</li> </ul>"},{"location":"research/causal-discovery/#the-challenge","title":"The Challenge","text":"<p>The fundamental challenge is that correlation \u2260 causation. Just because two variables are correlated doesn't mean one causes the other. They might both be caused by a third variable (confounding), or the correlation might be purely coincidental.</p>"},{"location":"research/causal-discovery/#approaches-to-causal-discovery","title":"Approaches to Causal Discovery","text":""},{"location":"research/causal-discovery/#1-constraint-based-methods","title":"1. Constraint-Based Methods","text":"<p>These methods use conditional independence tests to determine causal structure.</p> <p>Key Idea: If X and Y are independent given some set Z, then there's no direct causal relationship between X and Y.</p> <p>Popular Algorithms:</p> <ul> <li>PC Algorithm: Starts with a complete graph and removes edges based on independence tests</li> <li>FCI: Handles latent confounders and selection bias</li> </ul> <p>Example:  <pre><code>Temperature \u2192 Ice Cream Sales\nTemperature \u2192 Swimming\nSwimming \u2192 Drowning Incidents\n\nIce Cream Sales \u22a5 Drowning | Temperature\n</code></pre> Even though ice cream sales correlate with drowning, they're independent when we condition on temperature.</p>"},{"location":"research/causal-discovery/#2-score-based-methods","title":"2. Score-Based Methods","text":"<p>These methods search for the graph structure that best explains the data according to some scoring criterion.</p> <p>Key Idea: Among all possible causal graphs, choose the one that provides the best trade-off between fit to data and complexity.</p> <p>Popular Scores:</p> <ul> <li>BIC (Bayesian Information Criterion): Balances likelihood of data being generated by a particular causal graph with a penalty for the complexity of the graph</li> <li>BDeu (Baysian Dirichlet Equivaent Uniform): Bayesian score which modifies the likelihood of data being generated by a particular causal graph with some prior belief about the causal graph</li> </ul> <p>Process:</p> <ol> <li>Define a score function that measures how well a graph explains the data</li> <li>Search through possible graph structures</li> <li>Return the highest-scoring graph</li> </ol>"},{"location":"research/causal-discovery/#3-functional-causal-models","title":"3. Functional Causal Models","text":"<p>These methods assume specific functional relationships between variables.</p> <p>Key Idea: Use assumptions about the data-generating process (e.g., linearity, non-Gaussianity) to identify causal direction.</p> <p>Examples:</p> <ul> <li>ICA-based methods: Use non-Gaussianity to determine causal direction</li> <li>Nonlinear additive noise models: Exploit asymmetries in noise distributions</li> </ul>"},{"location":"research/causal-discovery/#practical-considerations","title":"Practical Considerations","text":""},{"location":"research/causal-discovery/#data-requirements","title":"Data Requirements","text":"<ul> <li>Sample size: More data generally leads to more reliable causal discovery</li> <li>Variable selection: Including relevant variables while avoiding irrelevant ones</li> <li>Data quality: Missing values and measurement error can affect results</li> </ul>"},{"location":"research/causal-discovery/#assumptions","title":"Assumptions","text":"<p>All causal discovery methods rely on assumptions:</p> <ul> <li>Faithfulness: The data distribution reflects the causal structure</li> <li>Causal sufficiency: All common causes are observed (or methods handle latent confounders)</li> <li>Stationarity: The causal structure doesn't change over time</li> </ul>"},{"location":"research/causal-discovery/#validation","title":"Validation","text":"<ul> <li>Cross-validation: Test stability across different data subsets</li> <li>Background knowledge: Incorporate domain expertise to validate results</li> <li>Intervention studies: When possible, test discovered relationships experimentally</li> </ul>"},{"location":"research/causal-discovery/#modern-developments","title":"Modern Developments","text":""},{"location":"research/causal-discovery/#ai-enhanced-causal-discovery","title":"AI-Enhanced Causal Discovery","text":"<p>Recent work explores how artificial intelligence can improve causal discovery:</p> <ul> <li>Domain knowledge integration: Using LLMs to incorporate expert knowledge</li> <li>Causal reasoning: AI systems that can reason about causation</li> <li>Automated interpretation: Natural language explanations of discovered relationships</li> </ul>"},{"location":"research/causal-discovery/#scalability","title":"Scalability","text":"<p>Modern methods handle larger, more complex datasets:</p> <ul> <li>Distributed algorithms: Parallel processing for large datasets</li> <li>Approximate methods: Trading accuracy for computational efficiency</li> <li>Online learning: Updating causal models as new data arrives</li> </ul>"},{"location":"research/causal-discovery/#getting-started","title":"Getting Started","text":""},{"location":"research/causal-discovery/#for-researchers","title":"For Researchers","text":"<ol> <li>Understand your domain: What causal relationships are you interested in?</li> <li>Choose appropriate methods: Consider your data type and assumptions</li> <li>Validate results: Use domain knowledge and cross-validation</li> <li>Interpret carefully: Remember the limitations and assumptions</li> </ol>"},{"location":"research/causal-discovery/#for-practitioners","title":"For Practitioners","text":"<ol> <li>Start simple: Begin with well-understood relationships</li> <li>Use multiple methods: Compare results across different algorithms</li> <li>Incorporate expertise: Combine algorithmic results with domain knowledge</li> <li>Test when possible: Validate discovered relationships through experiments</li> </ol> <p>Causal discovery is both an art and a science. While algorithms provide the computational power to analyze complex data, human insight and domain expertise remain essential for interpreting results and ensuring their validity.</p>"},{"location":"research/llm-integration/","title":"LLM Integration in Causal Discovery","text":"<p>The integration of Large Language Models (LLMs) with traditional causal discovery represents a frontier in AI-assisted scientific reasoning. This approach combines the statistical rigour of mathematical algorithms with the contextual understanding and reasoning capabilities of language models.</p>"},{"location":"research/llm-integration/#why-integrate-llms-with-causal-discovery","title":"Why Integrate LLMs with Causal Discovery?","text":""},{"location":"research/llm-integration/#addressing-traditional-limitations","title":"Addressing Traditional Limitations","text":"<p>Domain Knowledge Gap: Statistical algorithms operate purely on data, often missing crucial domain knowledge that experts possess.</p> <p>Interpretation Challenge: Raw algorithmic outputs can be difficult to interpret and validate without expert knowledge.</p> <p>Direction Ambiguity: Many statistical methods struggle to determine causal direction, especially when relationships are statistically equivalent.</p> <p>Scalability of Expertise: Human experts can't manually review every relationship in large causal graphs.</p>"},{"location":"research/llm-integration/#llm-capabilities-for-causal-reasoning","title":"LLM Capabilities for Causal Reasoning","text":"<p>Contextual Understanding: LLMs can interpret variable names, descriptions, and metadata to understand domain context.</p> <p>Prior Knowledge: Pre-trained on vast text corpora, LLMs encode substantial knowledge about causal relationships across domains.</p> <p>Natural Language Interface: Enable researchers to specify constraints and preferences in natural language.</p> <p>Explanation Generation: Provide human-readable explanations for discovered causal relationships.</p>"},{"location":"research/llm-integration/#integration-approaches","title":"Integration Approaches","text":""},{"location":"research/llm-integration/#1-prior-knowledge-injection","title":"1. Prior Knowledge Injection","text":"<p>LLMs can generate initial causal graph structures based on domain knowledge.</p> <p>Process: <pre><code># Natural language domain description\ndomain_knowledge = \"\"\"\nIn epidemiology, smoking causes lung cancer and heart disease.\nAir pollution independently affects respiratory health.\nGenetics influence both cancer susceptibility and smoking behavior.\n\"\"\"\n\n# LLM generates initial graph structure\nllm_prior = llm.generate_causal_graph(domain_knowledge, variables)\n\n# Statistical algorithm refines the structure\nrefined_graph = statistical_algorithm.learn(data, prior=llm_prior)\n</code></pre></p> <p>Benefits:</p> <ul> <li>Incorporates expert knowledge into automated discovery</li> <li>Provides better starting points for search algorithms</li> <li>Reduces search space by eliminating implausible relationships</li> </ul>"},{"location":"research/llm-integration/#2-constraint-generation","title":"2. Constraint Generation","text":"<p>LLMs can generate constraints that guide statistical learning.</p> <p>Types of Constraints:</p> <ul> <li>Forbidden edges: Relationships that are impossible or implausible</li> <li>Required edges: Relationships that must exist based on domain knowledge</li> <li>Direction constraints: When causal direction is known from theory</li> </ul> <p>Example: <pre><code>constraints = llm.generate_constraints(\n    domain=\"medical research\",\n    variables=[\"age\", \"smoking\", \"lung_cancer\", \"treatment\"],\n    context=\"longitudinal study of cancer patients\"\n)\n\n# Output might include:\n# - age \u2192 smoking (allowed, age can influence when someone starts smoking)\n# - smoking \u2192 age (forbidden, smoking can't cause age)\n# - treatment \u2192 lung_cancer (forbidden, treatment comes after diagnosis)\n</code></pre></p>"},{"location":"research/llm-integration/#3-post-processing-and-interpretation","title":"3. Post-Processing and Interpretation","text":"<p>LLMs can interpret and explain the results of statistical causal discovery.</p> <p>Capabilities:</p> <ul> <li>Plausibility checking: Evaluate whether discovered relationships make sense</li> <li>Explanation generation: Provide natural language explanations for relationships</li> <li>Conflict resolution: Help resolve contradictions between statistical evidence and domain knowledge</li> </ul> <p>Example Workflow: <pre><code># Statistical discovery finds: X \u2192 Y\nstatistical_result = algorithm.learn_structure(data)\n\n# LLM evaluates and explains\nevaluation = llm.evaluate_relationship(\n    cause=\"dietary_fiber\",\n    effect=\"cholesterol_levels\", \n    context=\"nutritional study\",\n    statistical_evidence=statistical_result.evidence\n)\n\n# LLM provides explanation:\n# \"This relationship is plausible. Dietary fiber can bind to cholesterol \n# in the digestive system, reducing absorption and lowering blood levels.\n# The negative correlation supports this causal direction.\"\n</code></pre></p>"},{"location":"research/llm-integration/#4-interactive-discovery","title":"4. Interactive Discovery","text":"<p>LLMs enable natural language interaction during the discovery process.</p> <p>Interactive Elements:</p> <ul> <li>Query-driven exploration of causal relationships</li> <li>Natural language specification of research questions</li> <li>Real-time hypothesis testing and refinement</li> </ul> <p>Example Session: <pre><code>Researcher: \"What factors influence customer satisfaction in our data?\"\n\nLLM: \"Based on the causal analysis, I found three main pathways:\n1. Product Quality \u2192 Customer Satisfaction (direct effect)\n2. Price \u2192 Perceived Value \u2192 Customer Satisfaction (mediated effect)\n3. Customer Service \u2192 Trust \u2192 Customer Satisfaction (trust-mediated)\n\nWould you like me to explore any of these pathways in more detail?\"\n\nResearcher: \"Tell me more about the price pathway.\"\n\nLLM: \"The price pathway shows that price doesn't directly affect satisfaction.\nInstead, price influences how customers perceive value (price-to-quality ratio),\nwhich then affects satisfaction. This suggests that competitive pricing\nstrategies should focus on value perception rather than just low prices.\"\n</code></pre></p>"},{"location":"research/llm-integration/#technical-implementation","title":"Technical Implementation","text":""},{"location":"research/llm-integration/#1-graph-representation-for-llms","title":"1. Graph Representation for LLMs","text":"<p>Convert causal graphs into natural language descriptions that LLMs can process:</p> <pre><code>def graph_to_text(graph, variable_descriptions):\n    \"\"\"Convert causal graph to natural language description.\"\"\"\n    descriptions = []\n    for cause, effects in graph.items():\n        cause_desc = variable_descriptions.get(cause, cause)\n        for effect in effects:\n            effect_desc = variable_descriptions.get(effect, effect)\n            descriptions.append(f\"{cause_desc} causes {effect_desc}\")\n    return \". \".join(descriptions)\n</code></pre>"},{"location":"research/llm-integration/#2-constraint-parsing","title":"2. Constraint Parsing","text":"<p>Parse LLM-generated constraints into formal representations:</p> <pre><code>def parse_constraints(llm_output):\n    \"\"\"Parse natural language constraints into formal constraints.\"\"\"\n    constraints = {\n        'forbidden_edges': [],\n        'required_edges': [],\n        'direction_constraints': []\n    }\n\n    # Use NLP to extract constraint types and variables\n    # Implementation would use pattern matching or fine-tuned models\n\n    return constraints\n</code></pre>"},{"location":"research/llm-integration/#3-confidence-integration","title":"3. Confidence Integration","text":"<p>Combine statistical confidence with LLM reasoning confidence:</p> <pre><code>def integrated_confidence(statistical_score, llm_confidence, domain_knowledge_strength):\n    \"\"\"Combine multiple sources of evidence for relationship confidence.\"\"\"\n\n    # Weighted combination based on evidence strength\n    total_confidence = (\n        0.6 * statistical_score +           # Statistical evidence\n        0.3 * llm_confidence +              # LLM reasoning confidence  \n        0.1 * domain_knowledge_strength     # Prior knowledge strength\n    )\n\n    return min(max(total_confidence, 0), 1)  # Clamp to [0,1]\n</code></pre>"},{"location":"research/llm-integration/#validation-and-quality-control","title":"Validation and Quality Control","text":""},{"location":"research/llm-integration/#1-cross-validation-of-llm-suggestions","title":"1. Cross-Validation of LLM Suggestions","text":"<p>Statistical Validation: Test LLM-suggested relationships against held-out data.</p> <p>Expert Review: Have domain experts evaluate LLM-generated constraints and explanations.</p> <p>Consistency Checking: Verify that LLM suggestions are logically consistent across related queries.</p>"},{"location":"research/llm-integration/#2-uncertainty-quantification","title":"2. Uncertainty Quantification","text":"<p>LLM Confidence: Model and report LLM uncertainty in suggestions.</p> <p>Sensitivity Analysis: Test how robust discoveries are to different LLM priors.</p> <p>Ensemble Methods: Use multiple LLMs or prompting strategies and combine results.</p>"},{"location":"research/llm-integration/#3-bias-detection-and-mitigation","title":"3. Bias Detection and Mitigation","text":"<p>Training Data Bias: Be aware that LLM knowledge reflects biases in training data.</p> <p>Confirmation Bias: Avoid using LLMs only to confirm existing hypotheses.</p> <p>Domain Specificity: Validate LLM knowledge for specific domains and contexts.</p>"},{"location":"research/llm-integration/#current-challenges","title":"Current Challenges","text":""},{"location":"research/llm-integration/#1-hallucination-and-reliability","title":"1. Hallucination and Reliability","text":"<p>LLMs can generate plausible but incorrect causal relationships, requiring careful validation.</p>"},{"location":"research/llm-integration/#2-context-length-limitations","title":"2. Context Length Limitations","text":"<p>Large causal graphs may exceed LLM context windows, requiring summarization or chunking strategies.</p>"},{"location":"research/llm-integration/#3-quantitative-reasoning","title":"3. Quantitative Reasoning","text":"<p>LLMs struggle with precise numerical relationships and statistical concepts.</p>"},{"location":"research/llm-integration/#4-domain-adaptation","title":"4. Domain Adaptation","text":"<p>General-purpose LLMs may lack specialized knowledge for specific research domains.</p>"},{"location":"research/llm-integration/#future-directions","title":"Future Directions","text":""},{"location":"research/llm-integration/#1-domain-specific-fine-tuning","title":"1. Domain-Specific Fine-Tuning","text":"<p>Training LLMs on domain-specific causal knowledge and research literature.</p>"},{"location":"research/llm-integration/#2-causal-reasoning-models","title":"2. Causal Reasoning Models","text":"<p>Developing LLMs specifically designed for causal reasoning tasks.</p>"},{"location":"research/llm-integration/#3-interactive-discovery-platforms","title":"3. Interactive Discovery Platforms","text":"<p>Building integrated platforms that seamlessly combine statistical algorithms with LLM reasoning.</p>"},{"location":"research/llm-integration/#4-automated-validation","title":"4. Automated Validation","text":"<p>Developing methods to automatically validate LLM suggestions against statistical evidence and domain knowledge.</p>"},{"location":"research/llm-integration/#best-practices","title":"Best Practices","text":""},{"location":"research/llm-integration/#1-use-llms-as-assistants-not-oracles","title":"1. Use LLMs as Assistants, Not Oracles","text":"<ul> <li>Always validate LLM suggestions with statistical evidence</li> <li>Use LLMs to generate hypotheses, not final conclusions</li> <li>Maintain human oversight in the discovery process</li> </ul>"},{"location":"research/llm-integration/#2-document-llm-contributions","title":"2. Document LLM Contributions","text":"<ul> <li>Record which parts of analysis used LLM input</li> <li>Maintain transparency about AI assistance in research</li> <li>Enable reproducibility by saving LLM interactions</li> </ul>"},{"location":"research/llm-integration/#3-combine-multiple-evidence-sources","title":"3. Combine Multiple Evidence Sources","text":"<ul> <li>Statistical evidence from data</li> <li>LLM reasoning from large-scale knowledge</li> <li>Expert domain knowledge</li> <li>Experimental validation when possible</li> </ul>"},{"location":"research/llm-integration/#4-iterate-and-refine","title":"4. Iterate and Refine","text":"<ul> <li>Use discovery results to improve LLM prompts and constraints</li> <li>Update domain knowledge based on new findings</li> <li>Continuously validate and improve the integration approach</li> </ul> <p>The integration of LLMs with causal discovery represents a promising direction for AI-assisted scientific reasoning. By thoughtfully combining statistical rigor with contextual understanding, we can build more powerful and interpretable tools for understanding causation in complex systems.</p>"}]}